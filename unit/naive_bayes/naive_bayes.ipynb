{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement a naive bayes classifier\n",
    "\n",
    "Follow this document to implement the naive bayes classifier.\n",
    "\n",
    "## Reference\n",
    "\n",
    "* [Naive Bayes 3: Gaussian example](https://www.youtube.com/watch?v=r1in0YNetG8)\n",
    "* [How To Implement Naive Bayes From Scratch in Python](https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/)\n",
    "\n",
    "## Dataset\n",
    "\n",
    "This exercise uses a homemade 2D dataset, where both dimensions are from Gaussian distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "\n",
    "# Make plots look pretty\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Generate dataset with `sklearn.datasets`\n",
    "np.random.seed(0)\n",
    "x, y = sklearn.datasets.make_gaussian_quantiles(n_samples=600, n_classes=5)\n",
    "\n",
    "# Split data\n",
    "train_x = x[:500]\n",
    "train_y = y[:500]\n",
    "test_x = x[500:]\n",
    "test_y = y[500:]\n",
    "\n",
    "# Plot the training data\n",
    "plt.scatter(x[:,0], x[:,1], s=40, c=y, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how a naive bayes classifier perform on the dataset\n",
    "\n",
    "Here we use the [GaussianNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html) of sklearn, which is suitable for Gaussian distributed data. BTW, it is worthy to see how `plot_decision_boundary()` works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(clf, x, y):\n",
    "    padding = 0.15\n",
    "    resolution = 0.01\n",
    "    \n",
    "    # Feature range\n",
    "    x0_min, x0_max = x[:,0].min(), x[:,0].max()\n",
    "    x1_min, x1_max = x[:,1].min(), x[:,1].max()\n",
    "    x0_range = x0_max - x0_min\n",
    "    x1_range = x1_max - x1_min\n",
    "    \n",
    "    # Add padding\n",
    "    x0_min -= x0_range * padding\n",
    "    x0_max += x0_range * padding\n",
    "    x1_min -= x1_range * padding\n",
    "    x1_max += x1_range * padding\n",
    "\n",
    "    # Create a meshgrid of points with the above ranges\n",
    "    xx0, xx1 = np.meshgrid(np.arange(x0_min, x0_max, resolution),\n",
    "                           np.arange(x1_min, x1_max, resolution))\n",
    "    \n",
    "    # Use `clf` to predict each point of the meshgrid\n",
    "    # `ravel()` turns a 2D array into a vector\n",
    "    # `c_` concatenates vectors\n",
    "    yy = clf.predict(np.c_[xx0.ravel(), xx1.ravel()])   \n",
    "\n",
    "    # Reshape the 1D predictions back to a 2D meshgrid\n",
    "    yy = yy.reshape(xx0.shape)\n",
    "    \n",
    "    # Plot the contours on the grid\n",
    "    plt.figure(figsize=(8,6))\n",
    "    cs = plt.contourf(xx0, xx1, yy, cmap=plt.cm.Spectral)\n",
    "    \n",
    "    # Plot the original data\n",
    "    plt.scatter(x[:,0], x[:,1], s=35, c=y, cmap=plt.cm.Spectral)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Take a look at `sklearn.naive_bayes.GaussianNB`\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_x, train_y)\n",
    "plot_decision_boundary(gnb, train_x, train_y)\n",
    "print(accuracy_score(test_y, gnb.predict(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do it yourself\n",
    "\n",
    "Finish the above code cell to implement a naive bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNB(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def split_dataset(self, x, y):\n",
    "        # Seperate x by their corresponding label (y). There are 5 classes in our dataset.\n",
    "        # Therefore, the output of this function is a dictionary with 5 keys:\n",
    "        # {\n",
    "        #   0: [[0.1, 0.5], [0.7, 0.05], ...],\n",
    "        #   1: [[0.2, 0.6], [0.5, 0.08], ...],\n",
    "        #   ....\n",
    "        # }\n",
    "        pass # TODO: remove pass and implement this function\n",
    "    \n",
    "    def compute_gaussian_params(self, data):\n",
    "        # Input: samples with the same label\n",
    "        # Output: Gaussian parameters (mean & standard deviation) of each feature\n",
    "        # The output for our 2D dataset is a list of 2 tuples:\n",
    "        # [(f1 mean, f1 stdev), (f2 mean, f2 stdev)]\n",
    "        \n",
    "        pass # TODO: remove pass and implement this function\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        seperated_by_class = self.split_dataset(x)\n",
    "        self.gaussian_params = {}\n",
    "        for label, data in seperated_by_class.items():\n",
    "            self.gaussian_params[label] = self.compute_gaussian_params(data)\n",
    "        # After this function, `self.gaussian_params` looks like\n",
    "        # {\n",
    "        # ------------------------------------------\n",
    "        #   class: [fea1(mean, var), fea(mean, var)]\n",
    "        # ------------------------------------------\n",
    "        #   0    : [(0.5, 0.28), (0.6, 0.08)],\n",
    "        #   1    : [(0.3, 0.04), (0.7, 0.14)],\n",
    "        #   ...\n",
    "        # }\n",
    "    \n",
    "    def probability_for_each_class(self, x):\n",
    "        # Use self.gaussian_params to compute probability for each class for input x\n",
    "        # The return array :\n",
    "        # [0.0013, 0.0112, 0.0192, 0.0169, 0.0100]\n",
    "        pass # TODO: remove pass and implement this function\n",
    "    \n",
    "    def calculate_probability(self, x, mean, stdev):\n",
    "        # calculate probability for an input feature\n",
    "        pass # TODO: remove pass and implement this function\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # Predict x, where x looks like [[0.12, 1.5], [0.56, 3.2], ...]\n",
    "        y_pred = []\n",
    "        for data in x:\n",
    "            class_prob = self.probability_for_each_class(data)\n",
    "            y_pred.append(np.argmax(class_prob))\n",
    "        return np.array(y_pred)\n",
    "    \n",
    "# TODO: change GaussianNB() to MyGaussianNB() once you finish the above code\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(train_x, train_y)\n",
    "plot_decision_boundary(gnb, train_x, train_y)\n",
    "print(accuracy_score(test_y, gnb.predict(test_x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
