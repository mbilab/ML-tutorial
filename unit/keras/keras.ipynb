{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "[Keras](https://keras.io/) 是一種較 Tensorflow 更高階的深度學習框架，可以使用更少量的程式碼來建立深度學習模型，可以先熟悉 [Tensorflow 單元](/notebooks/unit/tensorflow/tenforflow.ipynb)後再來閱讀本單元。Keras 使用更低階的深度學習框架作為後端引擎，目前支援如 CNTK、Tensorflow、Theano 等知名框架。本單元將介紹 Keras 中 Model 與 Layer 的用法，並實作一個圖片分類器。\n",
    "\n",
    "## 1. Model & Layer\n",
    "\n",
    "在 Keras，可以宣告一個 [Model](https://keras.io/models/about-keras-models/) 物件，並透過加入一層一層的 [Layer](https://keras.io/layers/about-keras-layers/) 來建構一個神經網路，神經網路的運算(例如訓練)都可以透過該 Model 物件來操作。下方程式區段使用了 Keras 中常見的 [Sequential Model](https://keras.io/models/sequential/)，並加入了四種 Layer：\n",
    "\n",
    "1. [Convolutional Layer](https://keras.io/layers/convolutional/)：卷積層在影像、圖片應用上，表現比全連結層(Keras 的 Dense Layer 更為優異)，參考[卷積神經網絡介紹](https://medium.com/@yehjames/4f8249d65d4f)。\n",
    "2. [Pooling Layer](https://keras.io/layers/pooling/#maxpooling2d)：池化層的工作是降採樣(down sampling)，以下方程式區段使用的 MaxPooling 為例，將每個 2x2 降採樣為該區域的最大值。\n",
    "3. [Flatten Layer](https://keras.io/layers/core/#flatten)：將原本多維度的資料拉平成一維，目的是讓前一層的輸出可以接到下一層(通常是全連接層)的輸入。\n",
    "4. [Dense Layer](https://keras.io/layers/core/#dense)：全連結層。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "model = Sequential() # Declare a sequential model\n",
    "\n",
    "# Add a 2D convolutional layer with 64 nodes, a 3x3 filter and relu as avtivation function\n",
    "# After this layer, `model.output_shape` is (None, 62, 62, 64)\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "\n",
    "# Add a 2D max pooling layer that pools the maximun value every 2x2 area\n",
    "# After this layer, `model.output_shape` is (None, 31, 31, 64)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add a flatten layer\n",
    "# After this layer, `model.output_shape` is (None, 61504)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 32 nodes and sigmoid as activation function\n",
    "# After this layer, `model.output_shape` is (None, 32)\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "\n",
    "# See `model`\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CIFAR-10\n",
    "\n",
    "CIFAR 的全名為 Canadian Institute for Advanced Research，是由加拿大政府出資並由多位科學家、工程師收集而成的圖片資料庫。[CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) 包含 60000 張 32x32x3 的 RGB 彩色圖片，共 10 種分類。其中 50000 張為訓練資料，10000 張為測試資料。  \n",
    "\n",
    "![CIFAR-10](./cifar_10.png)\n",
    "\n",
    "Keras 提供[整理好的 CIFAR-10 資料](https://keras.io/datasets/#cifar10-small-image-classification)，只要透過 `import` 就可以拿到對應的訓練與測試資料。用法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# show the i-th sample of the cifar-10 training set, try a different `i`\n",
    "i = 0\n",
    "matplotlib.pyplot.imshow(x_train[i])\n",
    "print('Category:', y_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 範例模型\n",
    "\n",
    "以下使用 Keras 實作兩種深度學習模型來進行 CIFAR-10 圖片分類。其中 DNN 只使用全連接層，而 CNN 多使用了卷積層。相較於 [Tensorflow 單元](/notebooks/unit/tensorflow/tenforflow.ipynb)的 MNIST 資料，CIFAR-10 的圖片比較複雜且為彩色，更能發揮卷積層的效果。也因此相較於 DNN，CNN 應該更容易得到好的結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "x_tr_dnn = x_train[:10000].astype('float32')\n",
    "x_te_dnn = x_test.astype('float32')\n",
    "\n",
    "x_tr_dnn = x_tr_dnn.reshape(-1, 3072)\n",
    "x_te_dnn = x_te_dnn.reshape(-1, 3072)\n",
    "\n",
    "x_tr_dnn /= 255\n",
    "x_te_dnn /= 255\n",
    "\n",
    "y_tr_dnn = to_categorical(y_train[:10000], num_classes=10)\n",
    "y_te_dnn = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# options\n",
    "epochs = 20\n",
    "batch_size = 128 \n",
    "learning_rate = 0.001\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit(x_tr_dnn, y_tr_dnn, batch_size=batch_size, epochs=epochs, shuffle=True, validation_data=(x_te_dnn, y_te_dnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "x_tr_cnn = x_train[:10000].astype('float32')\n",
    "x_te_cnn = x_test.astype('float32')\n",
    "\n",
    "x_tr_cnn /= 255\n",
    "x_te_cnn /= 255\n",
    "\n",
    "y_tr_cnn = to_categorical(y_train[:10000], num_classes=10)\n",
    "y_te_cnn = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# options\n",
    "epochs = 20\n",
    "batch_size = 128 \n",
    "learning_rate = 0.001\n",
    "\n",
    "# model\n",
    "model = Sequential()\n",
    "\n",
    "# the input shape for cifar-10 is (32, 32, 3)\n",
    "# use `Conv2D(#neurons, (filter_size))` to add convolutionary layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
    "\n",
    "# use `MaxPooling2D()` to add pooling layers\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# TODO: add more convolutionary and/or pooling layers here\n",
    "\n",
    "# in practice, fully-connected layers are added after convolutionary and pooling ones \n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit(x_tr_cnn, y_tr_cnn, batch_size=batch_size, epochs=epochs, shuffle=True, validation_data=(x_te_cnn, y_te_cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若依照以上範例的設定，經過 20 輪訓練後，DNN 可以到達約 40% 的正確率，而 CNN 可以達到約 50% 的正確率。請更改 DNN 或是 CNN 的架構來改善模型。提示：\n",
    "\n",
    "1. 調整訓練輪數(`epochs`)\n",
    "2. 調整批次大小(`batch_size`)\n",
    "3. 調整學習速率(`learning_rate`)\n",
    "4. 增加層數\n",
    "5. 調整每層的神經元數量"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
